# what service should have - the deployment which it want to expose, the port of pod and  port at which
# application is running
# pl refer https://kubernetes.io/docs/reference/kubernetes-api/service-resources/service-v1/

apiVersion: v1
# k8 artifacts
kind: Service
# its own name
metadata:
  name: backend
# deployment specs
spec:
  # select pods with lable app: second-app (pods may have multiple labels)
  # the pods in our case is having second label tier: backend
  # the pods can also be placed say with label tier: another-backend
  # so selecting just app: second-app is targetting all the tiers in which this app can be placed
  selector:
    app: second-app
  # ports specs
  ports:
  # IP protocol
  - protocol: "TCP"
    # port that will be exposed by this service
    port: 80
    # port number to access on the pods targeted by the service (mapped to application)
    targetPort: 3000
    # to allow traffic inside kinD cluster
    nodePort: 30001
  # type of service
  type: NodePort
---
# The deployment object first should have its own name , then the container and pod containing that container
# and then selecting this pod as a part of deployment

# refer https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/
# will list all details of enclosing specs
apiVersion: apps/v1
# Deployment is k8 artifact or k8 object
kind: Deployment
metadata:
  # name of deployment
  name: second-app-deployment
# deployment specs, how the deployment should be configured
spec:
  # how many pods, default is 1, even 0 can be given
  replicas: 1
  # pods specs, which deployment should have
  template:
    # pods should be labelled with
    # there is no need for kind: Pod  here as deployment will always have pod
    metadata:
      # pod should be labelled with
      labels:
        app: second-app
        tier: backend
    # how this pod should look like
    spec:
      # how containers should be created inside pods
      # for this deployment, how many replicas you create , all pods will have same container spec
      containers:
      # container name inside pod and image
      - name: second-app-container
        # you need to create this image and push to registry
        image: cbagade/kube-data-icemptyvol:v5
        # after setting vol at pod, we need to mount that on container on specific path
        # this application is already have data folder
        # so that text file will be available onto pod now, over volume
        volumeMounts:
        - mountPath: /app/userchanges
          # name of volume set on pod, there might be multiple volumes, so need names
          name: userchanges-volume
      # volumes are at container level on pods
      volumes:
      # following volumes can be used by containers then
      # this should be defined first and then the volumeMounts should be added to containers
      - name: userchanges-volume
        # will create emptyDir when pod starts and keeps directory alive as long as pod is alive
        # if container restarts, data survive , but if pods restart, the data is gone
        emptyDir: {}
  # what pods should be created as a part of deployment
  # see template section, where pods are labelled
  # those pods will be selected to form this deployment
  selector:
    # the labels will be matched based on labels of pods
    matchLabels:
      app: second-app
      tier: backend


# kubectl apply -f app_deployment.yaml
# GET app_2/api/v1/fruits change port to 30001 --> should give error that file not found
# POST  app_2/api/v1/fruits change port to 30001
# Verify the changes
# GET  app_2/api/v1/fruits change port to 30001
# GET  app_2/api/v1/fruits/error change port to 30001
# This action will put container in error state and restart (pod is not restarted)
# GET app_2/api/v1/fruits change port to 30001
# changes are available, so emptyDir can survice container restart
# kubectl delete -f app_deployment.yaml
# kubectl apply -f app_deployment.yaml
# GET app_2/api/v1/fruits change port to 30001
# changes are lost, so emptyDir can't survive pod restart
